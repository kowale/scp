
@misc{barber_conformal_2023,
	title = {Conformal prediction beyond exchangeability},
	url = {http://arxiv.org/abs/2202.13415},
	doi = {10.48550/arXiv.2202.13415},
	abstract = {Conformal prediction is a popular, modern technique for providing valid predictive inference for arbitrary machine learning models. Its validity relies on the assumptions of exchangeability of the data, and symmetry of the given model fitting algorithm as a function of the data. However, exchangeability is often violated when predictive models are deployed in practice. For example, if the data distribution drifts over time, then the data points are no longer exchangeable; moreover, in such settings, we might want to use a nonsymmetric algorithm that treats recent observations as more relevant. This paper generalizes conformal prediction to deal with both aspects: we employ weighted quantiles to introduce robustness against distribution drift, and design a new randomization technique to allow for algorithms that do not treat data points symmetrically. Our new methods are provably robust, with substantially less loss of coverage when exchangeability is violated due to distribution drift or other challenging features of real data, while also achieving the same coverage guarantees as existing conformal prediction methods if the data points are in fact exchangeable. We demonstrate the practical utility of these new tools with simulations and real-data experiments on electricity and election forecasting.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Barber, Rina Foygel and Candes, Emmanuel J. and Ramdas, Aaditya and Tibshirani, Ryan J.},
	month = mar,
	year = {2023},
	note = {arXiv:2202.13415 [stat]},
	keywords = {Statistics - Methodology},
	file = {Preprint PDF:/home/kon/Zotero/storage/PKR8FIJ2/Barber et al. - 2023 - Conformal prediction beyond exchangeability.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/L6JJ2Q2C/2202.html:text/html},
}

@misc{angelopoulos_theoretical_2024,
	title = {Theoretical {Foundations} of {Conformal} {Prediction}},
	url = {http://arxiv.org/abs/2411.11824},
	doi = {10.48550/arXiv.2411.11824},
	abstract = {This book is about conformal prediction and related inferential techniques that build on permutation tests and exchangeability. These techniques are useful in a diverse array of tasks, including hypothesis testing and providing uncertainty quantification guarantees for machine learning systems. Much of the current interest in conformal prediction is due to its ability to integrate into complex machine learning workflows, solving the problem of forming prediction sets without any assumptions on the form of the data generating distribution. Since contemporary machine learning algorithms have generally proven difficult to analyze directly, conformal prediction's main appeal is its ability to provide formal, finite-sample guarantees when paired with such methods. The goal of this book is to teach the reader about the fundamental technical arguments that arise when researching conformal prediction and related questions in distribution-free inference. Many of these proof strategies, especially the more recent ones, are scattered among research papers, making it difficult for researchers to understand where to look, which results are important, and how exactly the proofs work. We hope to bridge this gap by curating what we believe to be some of the most important results in the literature and presenting their proofs in a unified language, with illustrations, and with an eye towards pedagogy.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Angelopoulos, Anastasios N. and Barber, Rina Foygel and Bates, Stephen},
	month = nov,
	year = {2024},
	note = {arXiv:2411.11824 [math]},
	keywords = {Mathematics - Statistics Theory, Statistics - Machine Learning, Statistics - Methodology, Statistics - Statistics Theory},
	file = {Preprint PDF:/home/kon/Zotero/storage/KCW8SL78/Angelopoulos et al. - 2024 - Theoretical Foundations of Conformal Prediction.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/B27THVJ9/2411.html:text/html},
}

@misc{yang_object_2023,
	title = {Object {Pose} {Estimation} with {Statistical} {Guarantees}: {Conformal} {Keypoint} {Detection} and {Geometric} {Uncertainty} {Propagation}},
	shorttitle = {Object {Pose} {Estimation} with {Statistical} {Guarantees}},
	url = {http://arxiv.org/abs/2303.12246},
	doi = {10.48550/arXiv.2303.12246},
	abstract = {The two-stage object pose estimation paradigm first detects semantic keypoints on the image and then estimates the 6D pose by minimizing reprojection errors. Despite performing well on standard benchmarks, existing techniques offer no provable guarantees on the quality and uncertainty of the estimation. In this paper, we inject two fundamental changes, namely conformal keypoint detection and geometric uncertainty propagation, into the two-stage paradigm and propose the first pose estimator that endows an estimation with provable and computable worst-case error bounds. On one hand, conformal keypoint detection applies the statistical machinery of inductive conformal prediction to convert heuristic keypoint detections into circular or elliptical prediction sets that cover the groundtruth keypoints with a user-specified marginal probability (e.g., 90\%). Geometric uncertainty propagation, on the other, propagates the geometric constraints on the keypoints to the 6D object pose, leading to a Pose UnceRtainty SEt (PURSE) that guarantees coverage of the groundtruth pose with the same probability. The PURSE, however, is a nonconvex set that does not directly lead to estimated poses and uncertainties. Therefore, we develop RANdom SAmple averaGing (RANSAG) to compute an average pose and apply semidefinite relaxation to upper bound the worst-case errors between the average pose and the groundtruth. On the LineMOD Occlusion dataset we demonstrate: (i) the PURSE covers the groundtruth with valid probabilities; (ii) the worst-case error bounds provide correct uncertainty quantification; and (iii) the average pose achieves better or similar accuracy as representative methods based on sparse keypoints.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Yang, Heng and Pavone, Marco},
	month = mar,
	year = {2023},
	note = {arXiv:2303.12246 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Robotics},
	file = {Preprint PDF:/home/kon/Zotero/storage/59V3HH23/Yang and Pavone - 2023 - Object Pose Estimation with Statistical Guarantees Conformal Keypoint Detection and Geometric Uncer.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/253H2WPL/2303.html:text/html},
}

@misc{zhang_champ_2024,
	title = {{CHAMP}: {Conformalized} {3D} {Human} {Multi}-{Hypothesis} {Pose} {Estimators}},
	shorttitle = {{CHAMP}},
	url = {http://arxiv.org/abs/2407.06141},
	doi = {10.48550/arXiv.2407.06141},
	abstract = {We introduce CHAMP, a novel method for learning sequence-to-sequence, multi-hypothesis 3D human poses from 2D keypoints by leveraging a conditional distribution with a diffusion model. To predict a single output 3D pose sequence, we generate and aggregate multiple 3D pose hypotheses. For better aggregation results, we develop a method to score these hypotheses during training, effectively integrating conformal prediction into the learning process. This process results in a differentiable conformal predictor that is trained end2end with the 3D pose estimator. Post-training, the learned scoring model is used as the conformity score, and the 3D pose estimator is combined with a conformal predictor to select the most accurate hypotheses for downstream aggregation. Our results indicate that using a simple mean aggregation on the conformal prediction-filtered hypotheses set yields competitive results. When integrated with more sophisticated aggregation techniques, our method achieves state-of-the-art performance across various metrics and datasets while inheriting the probabilistic guarantees of conformal prediction.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Zhang, Harry and Carlone, Luca},
	month = may,
	year = {2024},
	note = {arXiv:2407.06141 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {Preprint PDF:/home/kon/Zotero/storage/SGBV6P3F/Zhang and Carlone - 2024 - CHAMP Conformalized 3D Human Multi-Hypothesis Pose Estimators.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/N7LM5K76/2407.html:text/html},
}

@misc{timans_adaptive_2024,
	title = {Adaptive {Bounding} {Box} {Uncertainties} via {Two}-{Step} {Conformal} {Prediction}},
	url = {http://arxiv.org/abs/2403.07263},
	doi = {10.48550/arXiv.2403.07263},
	abstract = {Quantifying a model's predictive uncertainty is essential for safety-critical applications such as autonomous driving. We consider quantifying such uncertainty for multi-object detection. In particular, we leverage conformal prediction to obtain uncertainty intervals with guaranteed coverage for object bounding boxes. One challenge in doing so is that bounding box predictions are conditioned on the object's class label. Thus, we develop a novel two-step conformal approach that propagates uncertainty in predicted class labels into the uncertainty intervals of bounding boxes. This broadens the validity of our conformal coverage guarantees to include incorrectly classified objects, thus offering more actionable safety assurances. Moreover, we investigate novel ensemble and quantile regression formulations to ensure the bounding box intervals are adaptive to object size, leading to a more balanced coverage. Validating our two-step approach on real-world datasets for 2D bounding box localization, we find that desired coverage levels are satisfied with practically tight predictive uncertainty intervals.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Timans, Alexander and Straehle, Christoph-Nikolas and Sakmann, Kaspar and Nalisnick, Eric},
	month = jul,
	year = {2024},
	note = {arXiv:2403.07263 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Preprint PDF:/home/kon/Zotero/storage/SRCN6AAP/Timans et al. - 2024 - Adaptive Bounding Box Uncertainties via Two-Step Conformal Prediction.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/PA97DAC6/2403.html:text/html},
}

@misc{parente_conformalized_2023,
	title = {Conformalized {Multimodal} {Uncertainty} {Regression} and {Reasoning}},
	url = {http://arxiv.org/abs/2309.11018},
	doi = {10.48550/arXiv.2309.11018},
	abstract = {This paper introduces a lightweight uncertainty estimator capable of predicting multimodal (disjoint) uncertainty bounds by integrating conformal prediction with a deep-learning regressor. We specifically discuss its application for visual odometry (VO), where environmental features such as flying domain symmetries and sensor measurements under ambiguities and occlusion can result in multimodal uncertainties. Our simulation results show that uncertainty estimates in our framework adapt sample-wise against challenging operating conditions such as pronounced noise, limited training data, and limited parametric size of the prediction model. We also develop a reasoning framework that leverages these robust uncertainty estimates and incorporates optical flow-based reasoning to improve prediction prediction accuracy. Thus, by appropriately accounting for predictive uncertainties of data-driven learning and closing their estimation loop via rule-based reasoning, our methodology consistently surpasses conventional deep learning approaches on all these challenging scenarios--pronounced noise, limited training data, and limited model size-reducing the prediction error by 2-3x.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Parente, Domenico and Darabi, Nastaran and Stutts, Alex C. and Tulabandhula, Theja and Trivedi, Amit Ranjan},
	month = sep,
	year = {2023},
	note = {arXiv:2309.11018 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Robotics},
	file = {Preprint PDF:/home/kon/Zotero/storage/XQECN6EN/Parente et al. - 2023 - Conformalized Multimodal Uncertainty Regression and Reasoning.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/L3DWM4JB/2309.html:text/html},
}

@misc{tibshirani_stat_2023,
	title = {Stat {241B} {Conformal} {Prediction}},
	url = {https://www.stat.berkeley.edu/~ryantibs/statlearn-s23/lectures/conformal.pdf},
	author = {Tibshirani, Ryan J.},
	year = {2023},
	file = {PDF:/home/kon/Zotero/storage/72S82VLK/Tibshirani - 2023 - Conformal Prediction.pdf:application/pdf},
}

@misc{vovk_randomness_2025,
	title = {Randomness, exchangeability, and conformal prediction},
	url = {http://arxiv.org/abs/2501.11689},
	doi = {10.48550/arXiv.2501.11689},
	abstract = {This note continues development of the functional theory of randomness, a modification of the algorithmic theory of randomness getting rid of unspecified additive constants. It introduces new kinds of confidence predictors, including randomness predictors (the most general confidence predictors based on the assumption of IID observations) and exchangeability predictors (the most general confidence predictors based on the assumption of exchangeable observations). The main result implies that both are close to conformal predictors and quantifies the difference between them.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Vovk, Vladimir},
	month = jan,
	year = {2025},
	note = {arXiv:2501.11689 [cs]},
	keywords = {Computer Science - Machine Learning, Mathematics - Statistics Theory, Statistics - Machine Learning, Statistics - Statistics Theory},
	file = {Preprint PDF:/home/kon/Zotero/storage/UYJQU4J9/Vovk - 2025 - Randomness, exchangeability, and conformal prediction.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/L6LGLAFT/2501.html:text/html},
}

@misc{feldman_learning_2025,
	title = {Learning {Robot} {Safety} from {Sparse} {Human} {Feedback} using {Conformal} {Prediction}},
	url = {http://arxiv.org/abs/2501.04823},
	doi = {10.48550/arXiv.2501.04823},
	abstract = {Ensuring robot safety can be challenging; user-defined constraints can miss edge cases, policies can become unsafe even when trained from safe data, and safety can be subjective. Thus, we learn about robot safety by showing policy trajectories to a human who flags unsafe behavior. From this binary feedback, we use the statistical method of conformal prediction to identify a region of states, potentially in learned latent space, guaranteed to contain a user-specified fraction of future policy errors. Our method is sample-efficient, as it builds on nearest neighbor classification and avoids withholding data as is common with conformal prediction. By alerting if the robot reaches the suspected unsafe region, we obtain a warning system that mimics the human's safety preferences with guaranteed miss rate. From video labeling, our system can detect when a quadcopter visuomotor policy will fail to steer through a designated gate. We present an approach for policy improvement by avoiding the suspected unsafe region. With it we improve a model predictive controller's safety, as shown in experimental testing with 30 quadcopter flights across 6 navigation tasks. Code and videos are provided.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Feldman, Aaron O. and Vincent, Joseph A. and Adang, Maximilian and Low, Jun En and Schwager, Mac},
	month = jan,
	year = {2025},
	note = {arXiv:2501.04823 [cs]},
	keywords = {Computer Science - Robotics, Mathematics - Optimization and Control, Statistics - Applications},
	file = {Preprint PDF:/home/kon/Zotero/storage/TI2RAB54/Feldman et al. - 2025 - Learning Robot Safety from Sparse Human Feedback using Conformal Prediction.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/ZFE4XWIP/2501.html:text/html},
}

@misc{andeol_confident_2023,
	title = {Confident {Object} {Detection} via {Conformal} {Prediction} and {Conformal} {Risk} {Control}: an {Application} to {Railway} {Signaling}},
	shorttitle = {Confident {Object} {Detection} via {Conformal} {Prediction} and {Conformal} {Risk} {Control}},
	url = {http://arxiv.org/abs/2304.06052},
	doi = {10.48550/arXiv.2304.06052},
	abstract = {Deploying deep learning models in real-world certified systems requires the ability to provide confidence estimates that accurately reflect their uncertainty. In this paper, we demonstrate the use of the conformal prediction framework to construct reliable and trustworthy predictors for detecting railway signals. Our approach is based on a novel dataset that includes images taken from the perspective of a train operator and state-of-the-art object detectors. We test several conformal approaches and introduce a new method based on conformal risk control. Our findings demonstrate the potential of the conformal prediction framework to evaluate model performance and provide practical guidance for achieving formally guaranteed uncertainty bounds.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Andéol, Léo and Fel, Thomas and Grancey, Florence De and Mossina, Luca},
	month = apr,
	year = {2023},
	note = {arXiv:2304.06052 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Preprint PDF:/home/kon/Zotero/storage/AYCGQA58/Andéol et al. - 2023 - Confident Object Detection via Conformal Prediction and Conformal Risk Control an Application to Ra.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/3CNGCD8S/2304.html:text/html},
}

@misc{angelopoulos_learn_2022,
	title = {Learn then {Test}: {Calibrating} {Predictive} {Algorithms} to {Achieve} {Risk} {Control}},
	shorttitle = {Learn then {Test}},
	url = {http://arxiv.org/abs/2110.01052},
	doi = {10.48550/arXiv.2110.01052},
	abstract = {We introduce a framework for calibrating machine learning models so that their predictions satisfy explicit, finite-sample statistical guarantees. Our calibration algorithms work with any underlying model and (unknown) data-generating distribution and do not require model refitting. The framework addresses, among other examples, false discovery rate control in multi-label classification, intersection-over-union control in instance segmentation, and the simultaneous control of the type-1 error of outlier detection and confidence set coverage in classification or regression. Our main insight is to reframe the risk-control problem as multiple hypothesis testing, enabling techniques and mathematical arguments different from those in the previous literature. We use the framework to provide new calibration methods for several core machine learning tasks, with detailed worked examples in computer vision and tabular medical data.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Angelopoulos, Anastasios N. and Bates, Stephen and Candès, Emmanuel J. and Jordan, Michael I. and Lei, Lihua},
	month = sep,
	year = {2022},
	note = {arXiv:2110.01052 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning, Statistics - Methodology},
	file = {Preprint PDF:/home/kon/Zotero/storage/BJGHE6GX/Angelopoulos et al. - 2022 - Learn then Test Calibrating Predictive Algorithms to Achieve Risk Control.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/5PRFQKVU/2110.html:text/html},
}

@misc{mossina_conformal_2024,
	title = {Conformal {Semantic} {Image} {Segmentation}: {Post}-hoc {Quantification} of {Predictive} {Uncertainty}},
	shorttitle = {Conformal {Semantic} {Image} {Segmentation}},
	url = {http://arxiv.org/abs/2405.05145},
	doi = {10.48550/arXiv.2405.05145},
	abstract = {We propose a post-hoc, computationally lightweight method to quantify predictive uncertainty in semantic image segmentation. Our approach uses conformal prediction to generate statistically valid prediction sets that are guaranteed to include the ground-truth segmentation mask at a predefined confidence level. We introduce a novel visualization technique of conformalized predictions based on heatmaps, and provide metrics to assess their empirical validity. We demonstrate the effectiveness of our approach on well-known benchmark datasets and image segmentation prediction models, and conclude with practical insights.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Mossina, Luca and Dalmau, Joseba and andéol, Léo},
	month = apr,
	year = {2024},
	note = {arXiv:2405.05145 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning},
	file = {Preprint PDF:/home/kon/Zotero/storage/5AKR4XH9/Mossina et al. - 2024 - Conformal Semantic Image Segmentation Post-hoc Quantification of Predictive Uncertainty.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/KMMKYA34/2405.html:text/html},
}

@misc{lee_transformer_2024,
	title = {Transformer {Conformal} {Prediction} for {Time} {Series}},
	url = {http://arxiv.org/abs/2406.05332},
	doi = {10.48550/arXiv.2406.05332},
	abstract = {We present a conformal prediction method for time series using the Transformer architecture to capture long-memory and long-range dependencies. Specifically, we use the Transformer decoder as a conditional quantile estimator to predict the quantiles of prediction residuals, which are used to estimate the prediction interval. We hypothesize that the Transformer decoder benefits the estimation of the prediction interval by learning temporal dependencies across past prediction residuals. Our comprehensive experiments using simulated and real data empirically demonstrate the superiority of the proposed method compared to the existing state-of-the-art conformal prediction methods.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Lee, Junghwan and Xu, Chen and Xie, Yao},
	month = jun,
	year = {2024},
	note = {arXiv:2406.05332 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Preprint PDF:/home/kon/Zotero/storage/6NLG3GMF/Lee et al. - 2024 - Transformer Conformal Prediction for Time Series.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/ZQE22S2Y/2406.html:text/html},
}

@misc{quach_conformal_2024,
	title = {Conformal {Language} {Modeling}},
	url = {http://arxiv.org/abs/2306.10193},
	doi = {10.48550/arXiv.2306.10193},
	abstract = {We propose a novel approach to conformal prediction for generative language models (LMs). Standard conformal prediction produces prediction sets -- in place of single predictions -- that have rigorous, statistical performance guarantees. LM responses are typically sampled from the model's predicted distribution over the large, combinatorial output space of natural language. Translating this process to conformal prediction, we calibrate a stopping rule for sampling different outputs from the LM that get added to a growing set of candidates until we are confident that the output set is sufficient. Since some samples may be low-quality, we also simultaneously calibrate and apply a rejection rule for removing candidates from the output set to reduce noise. Similar to conformal prediction, we prove that the sampled set returned by our procedure contains at least one acceptable answer with high probability, while still being empirically precise (i.e., small) on average. Furthermore, within this set of candidate responses, we show that we can also accurately identify subsets of individual components -- such as phrases or sentences -- that are each independently correct (e.g., that are not "hallucinations"), again with statistical guarantees. We demonstrate the promise of our approach on multiple tasks in open-domain question answering, text summarization, and radiology report generation using different LM variants.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Quach, Victor and Fisch, Adam and Schuster, Tal and Yala, Adam and Sohn, Jae Ho and Jaakkola, Tommi S. and Barzilay, Regina},
	month = jun,
	year = {2024},
	note = {arXiv:2306.10193 [cs]},
	keywords = {Computer Science - Computation and Language, Computer Science - Machine Learning},
	file = {Preprint PDF:/home/kon/Zotero/storage/XGLQGR4E/Quach et al. - 2024 - Conformal Language Modeling.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/UXMFY9A6/2306.html:text/html},
}

@misc{gibbs_conformal_2024,
	title = {Conformal {Prediction} {With} {Conditional} {Guarantees}},
	url = {http://arxiv.org/abs/2305.12616},
	doi = {10.48550/arXiv.2305.12616},
	abstract = {We consider the problem of constructing distribution-free prediction sets with finite-sample conditional guarantees. Prior work has shown that it is impossible to provide exact conditional coverage universally in finite samples. Thus, most popular methods only guarantee marginal coverage over the covariates or are restricted to a limited set of conditional targets, e.g. coverage over a finite set of pre-specified subgroups. This paper bridges this gap by defining a spectrum of problems that interpolate between marginal and conditional validity. We motivate these problems by reformulating conditional coverage as coverage over a class of covariate shifts. When the target class of shifts is finite-dimensional, we show how to simultaneously obtain exact finite-sample coverage over all possible shifts. For example, given a collection of subgroups, our prediction sets guarantee coverage over each group. For more flexible, infinite-dimensional classes where exact coverage is impossible, we provide a procedure for quantifying the coverage errors of our algorithm. Moreover, by tuning interpretable hyperparameters, we allow the practitioner to control the size of these errors across shifts of interest. Our methods can be incorporated into existing split conformal inference pipelines, and thus can be used to quantify the uncertainty of modern black-box algorithms without distributional assumptions.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Gibbs, Isaac and Cherian, John J. and Candès, Emmanuel J.},
	month = sep,
	year = {2024},
	note = {arXiv:2305.12616 [stat]},
	keywords = {Statistics - Methodology},
	file = {Preprint PDF:/home/kon/Zotero/storage/FFHER7S7/Gibbs et al. - 2024 - Conformal Prediction With Conditional Guarantees.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/UCSSE8IE/2305.html:text/html},
}

@misc{angelopoulos_conformal_2023,
	title = {Conformal {PID} {Control} for {Time} {Series} {Prediction}},
	url = {http://arxiv.org/abs/2307.16895},
	doi = {10.48550/arXiv.2307.16895},
	abstract = {We study the problem of uncertainty quantification for time series prediction, with the goal of providing easy-to-use algorithms with formal guarantees. The algorithms we present build upon ideas from conformal prediction and control theory, are able to prospectively model conformal scores in an online setting, and adapt to the presence of systematic errors due to seasonality, trends, and general distribution shifts. Our theory both simplifies and strengthens existing analyses in online conformal prediction. Experiments on 4-week-ahead forecasting of statewide COVID-19 death counts in the U.S. show an improvement in coverage over the ensemble forecaster used in official CDC communications. We also run experiments on predicting electricity demand, market returns, and temperature using autoregressive, Theta, Prophet, and Transformer models. We provide an extendable codebase for testing our methods and for the integration of new algorithms, data sets, and forecasting rules.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Angelopoulos, Anastasios N. and Candes, Emmanuel J. and Tibshirani, Ryan J.},
	month = jul,
	year = {2023},
	note = {arXiv:2307.16895 [cs]},
	keywords = {Computer Science - Machine Learning, Computer Science - Systems and Control, Electrical Engineering and Systems Science - Systems and Control, Statistics - Machine Learning, Statistics - Methodology},
	file = {Preprint PDF:/home/kon/Zotero/storage/243UIDD7/Angelopoulos et al. - 2023 - Conformal PID Control for Time Series Prediction.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/EPHWM2PG/2307.html:text/html},
}

@misc{huang_uncertainty_2023,
	title = {Uncertainty {Quantification} over {Graph} with {Conformalized} {Graph} {Neural} {Networks}},
	url = {http://arxiv.org/abs/2305.14535},
	doi = {10.48550/arXiv.2305.14535},
	abstract = {Graph Neural Networks (GNNs) are powerful machine learning prediction models on graph-structured data. However, GNNs lack rigorous uncertainty estimates, limiting their reliable deployment in settings where the cost of errors is significant. We propose conformalized GNN (CF-GNN), extending conformal prediction (CP) to graph-based models for guaranteed uncertainty estimates. Given an entity in the graph, CF-GNN produces a prediction set/interval that provably contains the true label with pre-defined coverage probability (e.g. 90\%). We establish a permutation invariance condition that enables the validity of CP on graph data and provide an exact characterization of the test-time coverage. Moreover, besides valid coverage, it is crucial to reduce the prediction set size/interval length for practical use. We observe a key connection between non-conformity scores and network structures, which motivates us to develop a topology-aware output correction model that learns to update the prediction and produces more efficient prediction sets/intervals. Extensive experiments show that CF-GNN achieves any pre-defined target marginal coverage while significantly reducing the prediction set/interval size by up to 74\% over the baselines. It also empirically achieves satisfactory conditional coverage over various raw and network features.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Huang, Kexin and Jin, Ying and Candès, Emmanuel and Leskovec, Jure},
	month = oct,
	year = {2023},
	note = {arXiv:2305.14535 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Preprint PDF:/home/kon/Zotero/storage/XMPRDJRC/Huang et al. - 2023 - Uncertainty Quantification over Graph with Conformalized Graph Neural Networks.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/GUQNACX5/2305.html:text/html},
}

@misc{tibshirani_stat_2023-1,
	title = {Stat {241B} {Conformal} {Prediction} {Under} {Distribution} {Shift}},
	url = {https://www.stat.berkeley.edu/~ryantibs/statlearn-s23/lectures/conformal_ds.pdf},
	author = {Tibshirani, Ryan J.},
	year = {2023},
}

@misc{angelopoulos_gentle_2022,
	title = {A {Gentle} {Introduction} to {Conformal} {Prediction} and {Distribution}-{Free} {Uncertainty} {Quantification}},
	url = {http://arxiv.org/abs/2107.07511},
	doi = {10.48550/arXiv.2107.07511},
	abstract = {Black-box machine learning models are now routinely used in high-risk settings, like medical diagnostics, which demand uncertainty quantification to avoid consequential model failures. Conformal prediction is a user-friendly paradigm for creating statistically rigorous uncertainty sets/intervals for the predictions of such models. Critically, the sets are valid in a distribution-free sense: they possess explicit, non-asymptotic guarantees even without distributional assumptions or model assumptions. One can use conformal prediction with any pre-trained model, such as a neural network, to produce sets that are guaranteed to contain the ground truth with a user-specified probability, such as 90\%. It is easy-to-understand, easy-to-use, and general, applying naturally to problems arising in the fields of computer vision, natural language processing, deep reinforcement learning, and so on. This hands-on introduction is aimed to provide the reader a working understanding of conformal prediction and related distribution-free uncertainty quantification techniques with one self-contained document. We lead the reader through practical theory for and examples of conformal prediction and describe its extensions to complex machine learning tasks involving structured outputs, distribution shift, time-series, outliers, models that abstain, and more. Throughout, there are many explanatory illustrations, examples, and code samples in Python. With each code sample comes a Jupyter notebook implementing the method on a real-data example; the notebooks can be accessed and easily run using our codebase.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Angelopoulos, Anastasios N. and Bates, Stephen},
	month = dec,
	year = {2022},
	note = {arXiv:2107.07511 [cs]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Mathematics - Statistics Theory, Statistics - Machine Learning, Statistics - Methodology, Statistics - Statistics Theory},
	file = {Preprint PDF:/home/kon/Zotero/storage/UT6BLABF/Angelopoulos and Bates - 2022 - A Gentle Introduction to Conformal Prediction and Distribution-Free Uncertainty Quantification.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/MKLG3F3K/2107.html:text/html},
}

@misc{recht_cover_2024,
	title = {Cover {Songs}},
	url = {https://www.argmin.net/p/cover-songs},
	author = {Recht, Ben},
	year = {2024},
}

@misc{hullman_conformal_2024,
	title = {Conformal prediction and people},
	url = {https://statmodeling.stat.columbia.edu/2024/03/15/conformal-prediction-and-people/},
	author = {Hullman, Jessica},
	year = {2024},
}

@misc{degenne_mathlib_prob_2024,
	title = {Basic probability in Mathlib},
	url = {https://leanprover-community.github.io/blog/posts/basic-probability-in-mathlib/},
	author = {Degenne, Rémy},
	year = {2024},
}

@misc{zhang_evaluating_2024,
	title = {Evaluating the {Utility} of {Conformal} {Prediction} {Sets} for {AI}-{Advised} {Image} {Labeling}},
	url = {http://arxiv.org/abs/2401.08876},
	doi = {10.48550/arXiv.2401.08876},
	abstract = {As deep neural networks are more commonly deployed in high-stakes domains, their black-box nature makes uncertainty quantification challenging. We investigate the presentation of conformal prediction sets--a distribution-free class of methods for generating prediction sets with specified coverage--to express uncertainty in AI-advised decision-making. Through a large online experiment, we compare the utility of conformal prediction sets to displays of Top-1 and Top-k predictions for AI-advised image labeling. In a pre-registered analysis, we find that the utility of prediction sets for accuracy varies with the difficulty of the task: while they result in accuracy on par with or less than Top-1 and Top-k displays for easy images, prediction sets offer some advantage in assisting humans in labeling out-of-distribution (OOD) images in the setting that we studied, especially when the set size is small. Our results empirically pinpoint practical challenges of conformal prediction sets and provide implications on how to incorporate them for real-world decision-making.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Zhang, Dongping and Chatzimparmpas, Angelos and Kamali, Negar and Hullman, Jessica},
	month = apr,
	year = {2024},
	note = {arXiv:2401.08876 [cs]},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Human-Computer Interaction, Computer Science - Machine Learning},
	file = {Preprint PDF:/home/kon/Zotero/storage/5VVZF689/Zhang et al. - 2024 - Evaluating the Utility of Conformal Prediction Sets for AI-Advised Image Labeling.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/V7L8ZJ3V/2401.html:text/html},
}

@misc{angelopoulos_conformal_2023-1,
	title = {Conformal {Risk} {Control}},
	url = {http://arxiv.org/abs/2208.02814},
	doi = {10.48550/arXiv.2208.02814},
	abstract = {We extend conformal prediction to control the expected value of any monotone loss function. The algorithm generalizes split conformal prediction together with its coverage guarantee. Like conformal prediction, the conformal risk control procedure is tight up to an \${\textbackslash}mathcal\{O\}(1/n)\$ factor. We also introduce extensions of the idea to distribution shift, quantile risk control, multiple and adversarial risk control, and expectations of U-statistics. Worked examples from computer vision and natural language processing demonstrate the usage of our algorithm to bound the false negative rate, graph distance, and token-level F1-score.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Angelopoulos, Anastasios N. and Bates, Stephen and Fisch, Adam and Lei, Lihua and Schuster, Tal},
	month = apr,
	year = {2023},
	note = {arXiv:2208.02814 [stat]},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Machine Learning, Mathematics - Statistics Theory, Statistics - Machine Learning, Statistics - Methodology, Statistics - Statistics Theory},
	file = {Preprint PDF:/home/kon/Zotero/storage/2RKCSQAR/Angelopoulos et al. - 2023 - Conformal Risk Control.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/Z6VVAWTJ/2208.html:text/html},
}

@misc{lekeufack_conformal_2024,
	title = {Conformal {Decision} {Theory}: {Safe} {Autonomous} {Decisions} from {Imperfect} {Predictions}},
	shorttitle = {Conformal {Decision} {Theory}},
	url = {http://arxiv.org/abs/2310.05921},
	doi = {10.48550/arXiv.2310.05921},
	abstract = {We introduce Conformal Decision Theory, a framework for producing safe autonomous decisions despite imperfect machine learning predictions. Examples of such decisions are ubiquitous, from robot planning algorithms that rely on pedestrian predictions, to calibrating autonomous manufacturing to exhibit high throughput and low error, to the choice of trusting a nominal policy versus switching to a safe backup policy at run-time. The decisions produced by our algorithms are safe in the sense that they come with provable statistical guarantees of having low risk without any assumptions on the world model whatsoever; the observations need not be I.I.D. and can even be adversarial. The theory extends results from conformal prediction to calibrate decisions directly, without requiring the construction of prediction sets. Experiments demonstrate the utility of our approach in robot motion planning around humans, automated stock trading, and robot manufacturing.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Lekeufack, Jordan and Angelopoulos, Anastasios N. and Bajcsy, Andrea and Jordan, Michael I. and Malik, Jitendra},
	month = may,
	year = {2024},
	note = {arXiv:2310.05921 [stat]},
	keywords = {Computer Science - Machine Learning, Computer Science - Robotics, Statistics - Machine Learning, Statistics - Methodology},
	file = {Preprint PDF:/home/kon/Zotero/storage/5WJ3FHP6/Lekeufack et al. - 2024 - Conformal Decision Theory Safe Autonomous Decisions from Imperfect Predictions.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/K8GKURSS/2310.html:text/html},
}

@misc{vovk_conditional_2012,
	title = {Conditional validity of inductive conformal predictors},
	url = {http://arxiv.org/abs/1209.2673},
	doi = {10.48550/arXiv.1209.2673},
	abstract = {Conformal predictors are set predictors that are automatically valid in the sense of having coverage probability equal to or exceeding a given confidence level. Inductive conformal predictors are a computationally efficient version of conformal predictors satisfying the same property of validity. However, inductive conformal predictors have been only known to control unconditional coverage probability. This paper explores various versions of conditional validity and various ways to achieve them using inductive conformal predictors and their modifications.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Vovk, Vladimir},
	month = sep,
	year = {2012},
	note = {arXiv:1209.2673 [cs]},
	keywords = {Computer Science - Machine Learning},
	file = {Preprint PDF:/home/kon/Zotero/storage/B88CFLM4/Vovk - 2012 - Conditional validity of inductive conformal predictors.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/TBTTZ9YN/1209.html:text/html},
}

@misc{xu_wasserstein-regularized_2025,
	title = {Wasserstein-regularized {Conformal} {Prediction} under {General} {Distribution} {Shift}},
	url = {http://arxiv.org/abs/2501.13430},
	doi = {10.48550/arXiv.2501.13430},
	abstract = {Conformal prediction yields a prediction set with guaranteed \$1-{\textbackslash}alpha\$ coverage of the true target under the i.i.d. assumption, which may not hold and lead to a gap between \$1-{\textbackslash}alpha\$ and the actual coverage. Prior studies bound the gap using total variation distance, which cannot identify the gap changes under distribution shift at a given \${\textbackslash}alpha\$. Besides, existing methods are mostly limited to covariate shift,while general joint distribution shifts are more common in practice but less researched.In response, we first propose a Wasserstein distance-based upper bound of the coverage gap and analyze the bound using probability measure pushforwards between the shifted joint data and conformal score distributions, enabling a separation of the effect of covariate and concept shifts over the coverage gap. We exploit the separation to design an algorithm based on importance weighting and regularized representation learning (WR-CP) to reduce the Wasserstein bound with a finite-sample error bound.WR-CP achieves a controllable balance between conformal prediction accuracy and efficiency. Experiments on six datasets prove that WR-CP can reduce coverage gaps to \$3.1{\textbackslash}\%\$ across different confidence levels and outputs prediction sets 38\${\textbackslash}\%\$ smaller than the worst-case approach on average.},
	urldate = {2025-01-30},
	publisher = {arXiv},
	author = {Xu, Rui and Chen, Chao and Sun, Yue and Venkitasubramaniam, Parvathinathan and Xie, Sihong},
	month = jan,
	year = {2025},
	note = {arXiv:2501.13430 [cs]},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Preprint PDF:/home/kon/Zotero/storage/V54PG4JU/Xu et al. - 2025 - Wasserstein-regularized Conformal Prediction under General Distribution Shift.pdf:application/pdf;Snapshot:/home/kon/Zotero/storage/7S5JKDQN/2501.html:text/html},
}
